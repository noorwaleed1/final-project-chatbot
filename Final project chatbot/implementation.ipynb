{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import json \n",
    "import pickle\n",
    "lem=PorterStemmer()\n",
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### intializing the necessary objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]   ## for lemmatized words\n",
    "classes=[]\n",
    "documents=[]  ## pattern with responses\n",
    "ignore_words=[\"?\",\",\",\"!\",\".\"]\n",
    "df=open(\"intents.json\")\n",
    "intents=json.load(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing (for me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for intent in intents['intents']:\n",
    "    ##print (intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        w=nltk.word_tokenize(pattern)\n",
    "        ##print(\"tokenized word is: {}\".format(w)) ## just ensurance\n",
    "        words.extend(w)     ## take all the iterables and extend them in the []\n",
    "        documents.append((w,intent['tag'])) ## appending the tokenized sentence with its class\n",
    "        ## adding the tag to classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "    ## final words list\n",
    "    ##print(\"words list is : {}\".format(words)) ## this is for ensurance (for me)\n",
    "    #print(\"docs is : {}\".format(documents))\n",
    "    #print(\"classes is : {}\".format(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stemming and lowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[lem.stem(w.lower())for w in words if w not in ignore_words] ## lowering and lemmatization\n",
    "words = list(set(words)) ## removing duplicates\n",
    "classes = list(set(classes))\n",
    "##print(words)\n",
    "pickle.dump(words,open('words.pkl','wb'))  ## saving into a pickle file\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noor waleed\\AppData\\Local\\Temp\\ipykernel_20196\\3393272716.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training=np.array(training)\n"
     ]
    }
   ],
   "source": [
    "training= []             ## we will have then bow \n",
    "output= [0]*len(classes) ## storing it with zero along with the length of the classes we have \n",
    "\n",
    "for doc in documents:\n",
    "    bag=[]\n",
    "    pattern_words=doc[0] ## (['Hi','there'],'greetings') 0 index is for the pattern itself\n",
    "    pattern_words=[lem.stem(word.lower())for word in pattern_words] ##lemmatizing the patterns\n",
    "    ##print(\"pattern words is : {}\".format(pattern_words))\n",
    "    for w in words:\n",
    "        bag.append(1)if w in pattern_words else bag.append(0)\n",
    "    ##print(\"bag is :{}\".format(bag))\n",
    "    output_row=list(output)\n",
    "    output_row[classes.index(doc[1])]=1\n",
    "   ## print(\"current output :{}\".format(output_row)) ## the output of the class\n",
    "     \n",
    "     \n",
    "    training.append([bag,output_row])\n",
    "##print(\"training data is:{}\".format(training))\n",
    "random.shuffle(training) ## avoids the overfit\n",
    "training=np.array(training)\n",
    "train_x=list(training[:,0]) ##bag\n",
    "train_y=list(training[:,1]) ## outputrow which has the classes\n",
    "##print(\"x:{}\".format(train_x))\n",
    "##print(\"y:{}\".format(train_y))\n",
    "   \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model with a simple seq model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(128,input_shape=(len(train_x[0]),),activation=\"relu\")) ## 128 neurons with number of input layer is the len of x\n",
    "model.add(Dropout(0.5)) ## activates a certain neurons for a better learn and avoiding the overfitting\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compile the model and define an optomization fuction with stochastic gradient decent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd=optimizers.SGD(learning_rate=0.003,decay=1e-6,momentum=0.9,nesterov=True) ## decay reduces the Lr the momentum and nesterov speed up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/199\n",
      "7/7 [==============================] - 3s 3ms/step - loss: 2.3240 - accuracy: 0.0588\n",
      "Epoch 2/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3935 - accuracy: 0.1471\n",
      "Epoch 3/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3172 - accuracy: 0.1176\n",
      "Epoch 4/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2699 - accuracy: 0.1176\n",
      "Epoch 5/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2376 - accuracy: 0.2059\n",
      "Epoch 6/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2824 - accuracy: 0.1471\n",
      "Epoch 7/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1827 - accuracy: 0.2059\n",
      "Epoch 8/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1091 - accuracy: 0.2353\n",
      "Epoch 9/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1079 - accuracy: 0.4118\n",
      "Epoch 10/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0542 - accuracy: 0.3529\n",
      "Epoch 11/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0245 - accuracy: 0.2647\n",
      "Epoch 12/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0883 - accuracy: 0.3529\n",
      "Epoch 13/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0779 - accuracy: 0.2941\n",
      "Epoch 14/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9998 - accuracy: 0.3235\n",
      "Epoch 15/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9364 - accuracy: 0.4706\n",
      "Epoch 16/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0126 - accuracy: 0.3824\n",
      "Epoch 17/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9786 - accuracy: 0.3824\n",
      "Epoch 18/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8744 - accuracy: 0.5000\n",
      "Epoch 19/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9025 - accuracy: 0.3824\n",
      "Epoch 20/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8642 - accuracy: 0.3529\n",
      "Epoch 21/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8670 - accuracy: 0.4706\n",
      "Epoch 22/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8704 - accuracy: 0.4412\n",
      "Epoch 23/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8052 - accuracy: 0.4412\n",
      "Epoch 24/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8187 - accuracy: 0.4706\n",
      "Epoch 25/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8061 - accuracy: 0.4706\n",
      "Epoch 26/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7165 - accuracy: 0.5588\n",
      "Epoch 27/199\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.6903 - accuracy: 0.5588\n",
      "Epoch 28/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.7752 - accuracy: 0.3824\n",
      "Epoch 29/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7457 - accuracy: 0.3824\n",
      "Epoch 30/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.5990 - accuracy: 0.5588\n",
      "Epoch 31/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.5744 - accuracy: 0.5000\n",
      "Epoch 32/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.5261 - accuracy: 0.6765\n",
      "Epoch 33/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.4772 - accuracy: 0.6176\n",
      "Epoch 34/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.4981 - accuracy: 0.5588\n",
      "Epoch 35/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.5614 - accuracy: 0.5294\n",
      "Epoch 36/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.4718 - accuracy: 0.5294\n",
      "Epoch 37/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3260 - accuracy: 0.6471\n",
      "Epoch 38/199\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3818 - accuracy: 0.6176\n",
      "Epoch 39/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3501 - accuracy: 0.7059\n",
      "Epoch 40/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2746 - accuracy: 0.6176\n",
      "Epoch 41/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1588 - accuracy: 0.7353\n",
      "Epoch 42/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2279 - accuracy: 0.7059\n",
      "Epoch 43/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1704 - accuracy: 0.7647\n",
      "Epoch 44/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3052 - accuracy: 0.6176\n",
      "Epoch 45/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2717 - accuracy: 0.5882\n",
      "Epoch 46/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1905 - accuracy: 0.6765\n",
      "Epoch 47/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2414 - accuracy: 0.6176\n",
      "Epoch 48/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9751 - accuracy: 0.8235\n",
      "Epoch 49/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1754 - accuracy: 0.6765\n",
      "Epoch 50/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9685 - accuracy: 0.7647\n",
      "Epoch 51/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2122 - accuracy: 0.6765\n",
      "Epoch 52/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8366 - accuracy: 0.9118\n",
      "Epoch 53/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8281 - accuracy: 0.7941\n",
      "Epoch 54/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8390 - accuracy: 0.7941\n",
      "Epoch 55/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.8529\n",
      "Epoch 56/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7634 - accuracy: 0.8824\n",
      "Epoch 57/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8322 - accuracy: 0.8824\n",
      "Epoch 58/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9489 - accuracy: 0.6765\n",
      "Epoch 59/199\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9423 - accuracy: 0.7647\n",
      "Epoch 60/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9057 - accuracy: 0.7647\n",
      "Epoch 61/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8298 - accuracy: 0.7941\n",
      "Epoch 62/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.7941\n",
      "Epoch 63/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.7353\n",
      "Epoch 64/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.9118\n",
      "Epoch 65/199\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6617 - accuracy: 0.8235\n",
      "Epoch 66/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.8235\n",
      "Epoch 67/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.7941\n",
      "Epoch 68/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.8235\n",
      "Epoch 69/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.8529\n",
      "Epoch 70/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.8235\n",
      "Epoch 71/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.8529\n",
      "Epoch 72/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.8529\n",
      "Epoch 73/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.9118\n",
      "Epoch 74/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8226 - accuracy: 0.7353\n",
      "Epoch 75/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.8824\n",
      "Epoch 76/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.8235\n",
      "Epoch 77/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8824\n",
      "Epoch 78/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.8529\n",
      "Epoch 79/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8824\n",
      "Epoch 80/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.8235\n",
      "Epoch 81/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8529\n",
      "Epoch 82/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.9412\n",
      "Epoch 83/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.9412\n",
      "Epoch 84/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8824\n",
      "Epoch 85/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.9118\n",
      "Epoch 86/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.9118\n",
      "Epoch 87/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.9412\n",
      "Epoch 88/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.9412\n",
      "Epoch 89/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.9118\n",
      "Epoch 90/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.9118\n",
      "Epoch 91/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8529\n",
      "Epoch 92/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8824\n",
      "Epoch 93/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.8824\n",
      "Epoch 94/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.9412\n",
      "Epoch 95/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8529\n",
      "Epoch 96/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.9118\n",
      "Epoch 97/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7941\n",
      "Epoch 98/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 1.0000\n",
      "Epoch 99/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8529\n",
      "Epoch 100/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8824\n",
      "Epoch 101/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.9412\n",
      "Epoch 102/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9412\n",
      "Epoch 103/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.9118\n",
      "Epoch 104/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.9118\n",
      "Epoch 105/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8824\n",
      "Epoch 106/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9706\n",
      "Epoch 107/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9706\n",
      "Epoch 108/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9706\n",
      "Epoch 109/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.9412\n",
      "Epoch 110/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9412\n",
      "Epoch 111/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.9706\n",
      "Epoch 112/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.9412\n",
      "Epoch 113/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.9118\n",
      "Epoch 114/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.9412\n",
      "Epoch 115/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8529\n",
      "Epoch 116/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8529\n",
      "Epoch 117/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.9118\n",
      "Epoch 118/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8824\n",
      "Epoch 119/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9118\n",
      "Epoch 120/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.9118\n",
      "Epoch 121/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2402 - accuracy: 0.9412\n",
      "Epoch 122/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9118\n",
      "Epoch 123/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9706\n",
      "Epoch 124/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9412\n",
      "Epoch 125/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8824\n",
      "Epoch 126/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9412\n",
      "Epoch 127/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 1.0000\n",
      "Epoch 128/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.9412\n",
      "Epoch 129/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9118\n",
      "Epoch 130/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9118\n",
      "Epoch 131/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8529\n",
      "Epoch 132/199\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 0.9706\n",
      "Epoch 133/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.9412\n",
      "Epoch 134/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.9118\n",
      "Epoch 135/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9412\n",
      "Epoch 136/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9706\n",
      "Epoch 137/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9706\n",
      "Epoch 138/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9412\n",
      "Epoch 139/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9706\n",
      "Epoch 140/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9706\n",
      "Epoch 141/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9706\n",
      "Epoch 142/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 1.0000\n",
      "Epoch 143/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.8824\n",
      "Epoch 144/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.9118\n",
      "Epoch 145/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 1.0000\n",
      "Epoch 146/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.9706\n",
      "Epoch 147/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9706\n",
      "Epoch 148/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 1.0000\n",
      "Epoch 149/199\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.9118\n",
      "Epoch 150/199\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.9706\n",
      "Epoch 151/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9706\n",
      "Epoch 152/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9412\n",
      "Epoch 153/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 1.0000\n",
      "Epoch 154/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9412\n",
      "Epoch 155/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 1.0000\n",
      "Epoch 156/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9706\n",
      "Epoch 157/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9412\n",
      "Epoch 158/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9412\n",
      "Epoch 159/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9706\n",
      "Epoch 160/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 1.0000\n",
      "Epoch 161/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 1.0000\n",
      "Epoch 162/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 1.0000\n",
      "Epoch 163/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9412\n",
      "Epoch 164/199\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9706\n",
      "Epoch 165/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9706\n",
      "Epoch 166/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 1.0000\n",
      "Epoch 167/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9706\n",
      "Epoch 168/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 1.0000\n",
      "Epoch 169/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9412\n",
      "Epoch 170/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 1.0000\n",
      "Epoch 171/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 1.0000\n",
      "Epoch 172/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 1.0000\n",
      "Epoch 173/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.9118\n",
      "Epoch 174/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 1.0000\n",
      "Epoch 175/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 1.0000\n",
      "Epoch 176/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.9412\n",
      "Epoch 177/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 1.0000\n",
      "Epoch 178/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 1.0000\n",
      "Epoch 179/199\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1856 - accuracy: 0.9706\n",
      "Epoch 180/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9706\n",
      "Epoch 181/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9706\n",
      "Epoch 182/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9706\n",
      "Epoch 183/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9118\n",
      "Epoch 184/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9706\n",
      "Epoch 185/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9118\n",
      "Epoch 186/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9412\n",
      "Epoch 187/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9706\n",
      "Epoch 188/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9706\n",
      "Epoch 189/199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9412\n",
      "Epoch 190/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 1.0000\n",
      "Epoch 191/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 1.0000\n",
      "Epoch 192/199\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 1.0000\n",
      "Epoch 193/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9706\n",
      "Epoch 194/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 1.0000\n",
      "Epoch 195/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9706\n",
      "Epoch 196/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9706\n",
      "Epoch 197/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 198/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9706\n",
      "Epoch 199/199\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "mfit=model.fit(np.array(train_x),np.array(train_y),epochs=199,batch_size=5,verbose=1) ## batch size is how many times do we change the parameters of our model\n",
    "model.save(\"chatbot_model.h5\",mfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
